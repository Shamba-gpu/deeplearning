{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yernar Shambayev, DL-2\n",
    "# Реализовать обучение линейной регрессии для задачи boston house prices\n",
    "# с использованием torch’а\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0     1     2   3      4      5     6       7   8      9     10  \\\n",
      "0  0.00632  18.0  2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
      "1  0.02731   0.0  7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
      "2  0.02729   0.0  7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
      "3  0.03237   0.0  2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
      "4  0.06905   0.0  2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
      "\n",
      "       11    12    13  \n",
      "0  396.90  4.98  24.0  \n",
      "1  396.90  9.14  21.6  \n",
      "2  392.83  4.03  34.7  \n",
      "3  394.63  2.94  33.4  \n",
      "4  396.90  5.33  36.2  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('housing.csv', header=None, delimiter=r\"\\s+\")\n",
    "print(df.head())\n",
    "features_data = df[df.columns[:-1]]\n",
    "features_data = features_data.apply(lambda x: (x - x.mean()) / x.std()) # Нормализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (102, 13) (404,) (102,)\n"
     ]
    }
   ],
   "source": [
    "features = features_data.to_numpy()\n",
    "labels = df[df.columns[-1]].to_numpy()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.2)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4186,  3.3717, -1.4455,  ..., -0.2566,  0.4300, -1.0983],\n",
      "        [-0.4183,  3.3717, -1.0767,  ..., -1.1804,  0.3249, -1.3364],\n",
      "        [ 0.3401, -0.4872,  1.0150,  ...,  0.8058,  0.3875, -1.3574],\n",
      "        ...,\n",
      "        [-0.3955,  0.0487, -0.4762,  ..., -1.5037,  0.3281,  2.4194],\n",
      "        [-0.4013,  0.3703, -0.6088,  ...,  0.0667,  0.4406, -0.8490],\n",
      "        [ 2.4633, -0.4872,  1.0150,  ...,  0.8058,  0.4406,  0.9966]])\n",
      "torch.Size([404, 13]) torch.Size([404, 1]) torch.FloatTensor torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float).view(-1, 1)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float).view(-1, 1)\n",
    "print(X_train)\n",
    "print(X_train.shape, Y_train.shape, X_train.type(), Y_train.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(torch.nn.Linear(13, 1))\n",
    "torch.nn.init.normal_(model[0].weight, mean=0, std=0.1)\n",
    "torch.nn.init.constant_(model[0].bias, val=0)\n",
    "\n",
    "datasets = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "train_iter = torch.utils.data.DataLoader(datasets, batch_size=10, shuffle=True)\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 198.47\n",
      "epoch 101, loss: 36.75\n",
      "epoch 201, loss: 10.35\n",
      "epoch 301, loss: 81.07\n",
      "epoch 401, loss: 82.69\n",
      "epoch 501, loss: 12.88\n",
      "epoch 601, loss: 68.39\n",
      "epoch 701, loss: 8.85\n",
      "epoch 801, loss: 9.92\n",
      "epoch 901, loss: 7.51\n"
     ]
    }
   ],
   "source": [
    "# Обучение\n",
    "num_epochs = 1000\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for x, y in train_iter:\n",
    "        output = model(x)\n",
    "        l = loss(output, y)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 1:\n",
    "        print(f\"epoch {epoch}, loss: {l.item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: 17.33361053466797\n",
      "\n",
      "Weights: Parameter containing:\n",
      "tensor([[-0.8003,  0.9713, -0.0501,  0.5733, -2.0612,  2.3547,  0.0678, -3.0003,\n",
      "          2.8213, -2.1549, -2.0479,  0.9963, -4.2588]], requires_grad=True), bias: Parameter containing:\n",
      "tensor([22.5321], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Тест\n",
    "print(f'\\nTest: {loss(model(X_test), Y_test).item()}\\n')\n",
    "\n",
    "# Веса\n",
    "print(f'Weights: {model[0].weight}, bias: {model[0].bias}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
