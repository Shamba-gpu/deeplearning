{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yernar Shambayev, DL-2\n",
    "# Решить задачу перевода с помощью механизма внимания\n",
    "# 1. Возьмите англо-русскую пару фраз (https://www.manythings.org/anki/)\n",
    "# 2. Обучите на них seq2seq with attention (на основе скалярного произведения, на основе MLP)\n",
    "# Оцените качество\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.nl import Dutch\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2623 3321\n"
     ]
    }
   ],
   "source": [
    "# Возьмем для разнообразия англо-голландский корпус\n",
    "\n",
    "with open(\"nld.txt\",\"r+\") as file:\n",
    "    holland = [x[:-1] for x in file.readlines()]\n",
    "en = []\n",
    "nld = []\n",
    "for line in holland:\n",
    "    en.append(line.split(\"\\t\")[0])\n",
    "    nld.append(line.split(\"\\t\")[1])\n",
    "\n",
    "training_examples = 10000\n",
    "spacy_en = English()\n",
    "spacy_nld = Dutch()\n",
    "\n",
    "en_words = Counter()\n",
    "nld_words = Counter()\n",
    "en_inputs = []\n",
    "nld_inputs = []\n",
    "\n",
    "# Токенизация\n",
    "for i in range(training_examples):\n",
    "    en_tokens = spacy_en(en[i])\n",
    "    nld_tokens = spacy_nld(nld[i])\n",
    "    if len(en_tokens)==0 or len(nld_tokens)==0:\n",
    "        continue\n",
    "        \n",
    "    for token in en_tokens:\n",
    "        en_words.update([token.text.lower()])\n",
    "    en_inputs.append([token.text.lower() for token in en_tokens] + ['_EOS'])\n",
    "    for token in nld_tokens:\n",
    "        nld_words.update([token.text.lower()])\n",
    "    nld_inputs.append([token.text.lower() for token in nld_tokens] + ['_EOS'])\n",
    "\n",
    "en_words = ['_SOS','_EOS','_UNK'] + sorted(en_words,key=en_words.get,reverse=True)\n",
    "en_w2i = {o:i for i,o in enumerate(en_words)}\n",
    "en_i2w = {i:o for i,o in enumerate(en_words)}\n",
    "nld_words = ['_SOS','_EOS','_UNK'] + sorted(nld_words,key=nld_words.get,reverse=True)\n",
    "nld_w2i = {o:i for i,o in enumerate(nld_words)}\n",
    "nld_i2w = {i:o for i,o in enumerate(nld_words)}\n",
    "\n",
    "for i in range(len(en_inputs)):\n",
    "    en_sentence = en_inputs[i]\n",
    "    nld_sentence = nld_inputs[i]\n",
    "    en_inputs[i] = [en_w2i[word] for word in en_sentence]\n",
    "    nld_inputs[i] = [nld_w2i[word] for word in nld_sentence]\n",
    "    \n",
    "print(len(en_words), len(nld_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Классы для скалярного произведения (Dot_Decoder), на основе MLP (MLP_Decoder)\n",
    "\n",
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, drop_prob=0):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=drop_prob, batch_first=True)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        embedded = self.embedding(inputs)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device),\n",
    "                torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device))\n",
    "\n",
    "class MLP_Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, drop_prob=0.1):\n",
    "        super(BahdanauDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "\n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.dropout = nn.Dropout(self.drop_prob)\n",
    "        self.lstm = nn.LSTM(self.hidden_size*2, self.hidden_size, batch_first=True)\n",
    "        self.classifier = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, inputs, hidden, encoder_outputs):\n",
    "        encoder_outputs = encoder_outputs.squeeze()\n",
    "\n",
    "        embedded = self.embedding(inputs).view(1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        x = torch.tanh(self.fc_hidden(hidden[0])+self.fc_encoder(encoder_outputs))\n",
    "        alignment_scores = x.bmm(self.weight.unsqueeze(2))  \n",
    "\n",
    "        attn_weights = F.softmax(alignment_scores.view(1,-1), dim=1)\n",
    "\n",
    "        context_vector = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded, context_vector[0]), 1).unsqueeze(0)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = F.log_softmax(self.classifier(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "class Dot_Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, attention, n_layers=1, drop_prob=0.1):\n",
    "        super(Dot_Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.drop_prob)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "        self.classifier = nn.Linear(self.hidden_size*2, self.output_size)\n",
    "    \n",
    "    def forward(self, inputs, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(inputs).view(1,1,-1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        lstm_out, hidden = self.lstm(embedded, hidden)\n",
    "\n",
    "        alignment_scores = self.attention(lstm_out,encoder_outputs)\n",
    "        attn_weights = F.softmax(alignment_scores.view(1,-1), dim=1)\n",
    "\n",
    "        context_vector = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs)\n",
    "\n",
    "        output = torch.cat((lstm_out, context_vector),-1)\n",
    "        output = F.log_softmax(self.classifier(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size, method=\"dot\"):\n",
    "        super(Attention, self).__init__()\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if method == \"general\":\n",
    "            self.fc = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "\n",
    "        elif method == \"concat\":\n",
    "            self.fc = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "            self.weight = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "  \n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        if self.method == \"dot\":\n",
    "          return encoder_outputs.bmm(decoder_hidden.view(1,-1,1)).squeeze(-1)\n",
    "    \n",
    "        elif self.method == \"general\":\n",
    "            out = self.fc(decoder_hidden)\n",
    "            return encoder_outputs.bmm(out.view(1,-1,1)).squeeze(-1)\n",
    "\n",
    "        elif self.method == \"concat\":\n",
    "            out = torch.tanh(self.fc(decoder_hidden+encoder_outputs))\n",
    "            return out.bmm(self.weight.unsqueeze(-1)).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "hidden_size = 256\n",
    "encoder = EncoderLSTM(len(en_words), hidden_size).to(device)\n",
    "attn = Attention(hidden_size,\"concat\")\n",
    "decoder = Dot_Decoder(hidden_size,len(nld_words),attn).to(device)\n",
    "\n",
    "lr = 0.001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 1, потери: 3.1886707433819774\n",
      "Эпоха: 2, потери: 2.1686106621755212\n",
      "Эпоха: 3, потери: 1.6647057241053291\n",
      "Эпоха: 4, потери: 1.328551610455762\n",
      "Эпоха: 5, потери: 1.0579434494096769\n",
      "Эпоха: 6, потери: 0.8824573078539446\n",
      "Эпоха: 7, потери: 0.7620667414881795\n",
      "Эпоха: 8, потери: 0.6655963821187009\n",
      "Эпоха: 9, потери: 0.6352166065754693\n",
      "Эпоха: 10, потери: 0.5822985703860916\n"
     ]
    }
   ],
   "source": [
    "# Обучение\n",
    "\n",
    "EPOCHS = 10\n",
    "teacher_forcing_prob = 0.5\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    avg_loss = 0.\n",
    "    for i, sentence in enumerate(en_inputs):\n",
    "        loss = 0.\n",
    "        h = encoder.init_hidden()\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        inp = torch.tensor(sentence).unsqueeze(0).to(device)\n",
    "        encoder_outputs, h = encoder(inp,h)\n",
    "        \n",
    "        decoder_input = torch.tensor([en_w2i['_SOS']],device=device)\n",
    "        decoder_hidden = h\n",
    "        output = []\n",
    "        teacher_forcing = True if random.random() < teacher_forcing_prob else False\n",
    "        \n",
    "        for ii in range(len(nld_inputs[i])):\n",
    "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "           \n",
    "            top_value, top_index = decoder_output.topk(1)\n",
    "            if teacher_forcing:\n",
    "                decoder_input = torch.tensor([nld_inputs[i][ii]],device=device)\n",
    "            else:\n",
    "                decoder_input = torch.tensor([top_index.item()],device=device)\n",
    "            output.append(top_index.item())\n",
    "            \n",
    "            loss += F.nll_loss(decoder_output.view(1,-1), torch.tensor([nld_inputs[i][ii]],device=device))\n",
    "        loss = loss/len(nld_inputs[i])\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        avg_loss += loss.item()/len(en_inputs)\n",
    "    print(f'Эпоха: {epoch}, потери: {avg_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входная фраза на английском языке: let 's stop here . _EOS\n",
      "Предсказание: laten we hier stoppen .\n",
      "Выходная фраза на голландском языке: laten we hier stoppen . _EOS\n"
     ]
    }
   ],
   "source": [
    "# Проверка качества\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "i = random.randint(0,len(en_inputs)-1)\n",
    "h = encoder.init_hidden()\n",
    "inp = torch.tensor(en_inputs[i]).unsqueeze(0).to(device)\n",
    "encoder_outputs, h = encoder(inp,h)\n",
    "\n",
    "decoder_input = torch.tensor([en_w2i['_SOS']],device=device)\n",
    "decoder_hidden = h\n",
    "output = []\n",
    "attentions = []\n",
    "while True:\n",
    "    decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "    _, top_index = decoder_output.topk(1)\n",
    "    decoder_input = torch.tensor([top_index.item()],device=device)\n",
    "    \n",
    "    if top_index.item() == nld_w2i[\"_EOS\"]:\n",
    "        break\n",
    "    output.append(top_index.item())\n",
    "    attentions.append(attn_weights.squeeze().cpu().detach().numpy())\n",
    "    \n",
    "print(\"Входная фраза на английском языке: \"+ \" \".join([en_i2w[x] for x in en_inputs[i]]))\n",
    "print(\"Предсказание: \" + \" \".join([nld_i2w[x] for x in output]))\n",
    "print(\"Выходная фраза на голландском языке: \" + \" \".join([nld_i2w[x] for x in nld_inputs[i]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
