{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yernar Shambayev, DL-2\n",
    "# Реализуйте задачу машинного перевода с использованием transformer. Датасет: \n",
    "# http://www.manythings.org/anki/\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего предложений: 3812\n"
     ]
    }
   ],
   "source": [
    "# Возьмем англо-белорусский корпус\n",
    "\n",
    "with open(\"bel.txt\") as f:\n",
    "    sentences = f.readlines()\n",
    "print(f'Всего предложений: {len(sentences)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1921, 80, 1640, 857, 2206, 788, 1946, 1037, 1037, 1037]\n",
      "['<sos>', 'you', 're', 'the', 'tallest', 'one', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "[3477, 3779, 2749, 3507, 1920, 1920, 1920, 1920, 1920, 1920]\n",
      "['<sos>', 'ты', 'найвышэйшы', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "\n",
      "[1921, 1361, 2133, 80, 1640, 688, 1946, 1037, 1037, 1037]\n",
      "['<sos>', 'i', 'know', 'you', 're', 'hungry', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "[3477, 2896, 3893, 2279, 3779, 142, 3507, 1920, 1920, 1920]\n",
      "['<sos>', 'я', 'ведаю', 'што', 'ты', 'галодная', '<eos>', '<pad>', '<pad>', '<pad>']\n",
      "\n",
      "[1921, 1660, 754, 1946, 1037, 1037, 1037, 1037, 1037, 1037]\n",
      "['<sos>', 'call', 'us', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "[3477, 679, 2404, 3507, 1920, 1920, 1920, 1920, 1920, 1920]\n",
      "['<sos>', 'пакліч', 'нас', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "\n",
      "[1921, 62, 2102, 1451, 1200, 857, 513, 952, 390, 857]\n",
      "['<sos>', 'millions', 'of', 'people', 'across', 'the', 'world', 'are', 'mourning', 'the']\n",
      "[3477, 895, 1809, 551, 3868, 2580, 2313, 1551, 26, 921]\n",
      "['<sos>', 'мільёны', 'людзей', 'ва', 'ўсім', 'свеце', 'аплакваюць', 'смерць', 'нэльсана', 'мандэлы']\n",
      "\n",
      "[1921, 674, 1252, 1079, 80, 1946, 1037, 1037, 1037, 1037]\n",
      "['<sos>', 'we', 'can', 'help', 'you', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "[3477, 1241, 476, 1253, 3952, 3507, 1920, 1920, 1920, 1920]\n",
      "['<sos>', 'мы', 'можам', 'табе', 'дапамагчы', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Препроцессинг\n",
    "\n",
    "MAX_NUM = 10000\n",
    "MAX_SENT_LEN = 10\n",
    "eng_sentences, bel_sentences = [], []\n",
    "eng_words, bel_words = set(), set()\n",
    "\n",
    "for i in range(MAX_NUM):\n",
    "    rand_idx = np.random.randint(len(sentences))\n",
    "\n",
    "    eng_sent, bel_sent = [\"<sos>\"], [\"<sos>\"]\n",
    "    eng_sent += re.findall(r\"\\w+\", sentences[rand_idx].split(\"\\t\")[0]) \n",
    "    bel_sent += re.findall(r\"\\w+\", sentences[rand_idx].split(\"\\t\")[1])\n",
    "\n",
    "    eng_sent = [x.lower() for x in eng_sent]\n",
    "    bel_sent = [x.lower() for x in bel_sent]\n",
    "    eng_sent.append(\"<eos>\")\n",
    "    bel_sent.append(\"<eos>\")\n",
    "\n",
    "    if len(eng_sent) >= MAX_SENT_LEN:\n",
    "        eng_sent = eng_sent[:MAX_SENT_LEN]\n",
    "    else:\n",
    "        for _ in range(MAX_SENT_LEN - len(eng_sent)):\n",
    "            eng_sent.append(\"<pad>\")\n",
    "\n",
    "    if len(bel_sent) >= MAX_SENT_LEN:\n",
    "        bel_sent = bel_sent[:MAX_SENT_LEN]\n",
    "    else:\n",
    "        for _ in range(MAX_SENT_LEN - len(bel_sent)):\n",
    "            bel_sent.append(\"<pad>\")\n",
    "\n",
    "    eng_sentences.append(eng_sent)\n",
    "    bel_sentences.append(bel_sent)\n",
    "\n",
    "    eng_words.update(eng_sent)\n",
    "    bel_words.update(bel_sent)\n",
    "\n",
    "eng_words, bel_words = list(eng_words), list(bel_words)\n",
    "\n",
    "for i in range(len(eng_sentences)):\n",
    "    eng_sentences[i] = [eng_words.index(x) for x in eng_sentences[i]]\n",
    "    bel_sentences[i] = [bel_words.index(x) for x in bel_sentences[i]]\n",
    "\n",
    "for i in range(5):\n",
    "    print(eng_sentences[i])\n",
    "    print([eng_words[x] for x in eng_sentences[i]])\n",
    "    print(bel_sentences[i])\n",
    "    print([bel_words[x] for x in bel_sentences[i]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Устанавливаем гиперпараметры\n",
    "\n",
    "ENG_VOCAB_SIZE = len(eng_words)\n",
    "BEL_VOCAB_SIZE = len(bel_words)\n",
    "NUM_EPOCHS = 10\n",
    "HIDDEN_SIZE = 16\n",
    "EMBEDDING_DIM = 30\n",
    "BATCH_SIZE = 128\n",
    "NUM_HEADS = 2\n",
    "NUM_LAYERS = 3\n",
    "LEARNING_RATE = 0.01\n",
    "DROPOUT = 0.3\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем в датасет\n",
    "\n",
    "class Vocab_Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(self):  \n",
    "    self.source = np.array(eng_sentences, dtype = int)\n",
    "    self.target = np.array(bel_sentences, dtype = int)\n",
    "    \n",
    "  def __getitem__(self, idx):\n",
    "    return self.source[idx], self.target[idx]\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.source)\n",
    "\n",
    "np.random.seed(777)   \n",
    "dataset = Vocab_Dataset()\n",
    "NUM_INSTANCES = len(dataset)\n",
    "TEST_RATIO = 0.3\n",
    "TEST_SIZE = int(NUM_INSTANCES * 0.3)\n",
    "\n",
    "indices = list(range(NUM_INSTANCES))\n",
    "\n",
    "test_idx = np.random.choice(indices, size = TEST_SIZE, replace = False)\n",
    "train_idx = list(set(indices) - set(test_idx))\n",
    "train_sampler, test_sampler = SubsetRandomSampler(train_idx), SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size = BATCH_SIZE, sampler = train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size = BATCH_SIZE, sampler = test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Взято: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сам трансформер\n",
    "\n",
    "class TransformerNet(nn.Module):\n",
    "  def __init__(self, num_src_vocab, num_tgt_vocab, embedding_dim, hidden_size, nheads, n_layers, max_src_len, max_tgt_len, dropout):\n",
    "    super(TransformerNet, self).__init__()\n",
    "\n",
    "    self.enc_embedding = nn.Embedding(num_src_vocab, embedding_dim)\n",
    "    self.dec_embedding = nn.Embedding(num_tgt_vocab, embedding_dim)\n",
    "\n",
    "    self.enc_pe = PositionalEncoding(embedding_dim, max_len = max_src_len)\n",
    "    self.dec_pe = PositionalEncoding(embedding_dim, max_len = max_tgt_len)\n",
    "\n",
    "    enc_layer = nn.TransformerEncoderLayer(embedding_dim, nheads, hidden_size, dropout)\n",
    "    dec_layer = nn.TransformerDecoderLayer(embedding_dim, nheads, hidden_size, dropout)\n",
    "    self.encoder = nn.TransformerEncoder(enc_layer, num_layers = n_layers)\n",
    "    self.decoder = nn.TransformerDecoder(dec_layer, num_layers = n_layers)\n",
    "\n",
    "    self.dense = nn.Linear(embedding_dim, num_tgt_vocab)\n",
    "    self.log_softmax = nn.LogSoftmax()\n",
    "\n",
    "  def forward(self, src, tgt):\n",
    "    src, tgt = self.enc_embedding(src).permute(1, 0, 2), self.dec_embedding(tgt).permute(1, 0, 2)\n",
    "    src, tgt = self.enc_pe(src), self.dec_pe(tgt)\n",
    "    memory = self.encoder(src)\n",
    "    transformer_out = self.decoder(tgt, memory)\n",
    "    final_out = self.dense(transformer_out)\n",
    "    return self.log_softmax(final_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerNet(ENG_VOCAB_SIZE, BEL_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_SIZE, NUM_HEADS, NUM_LAYERS, MAX_SENT_LEN, MAX_SENT_LEN, DROPOUT).to(DEVICE)\n",
    "loss = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taisa/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 1, режим: train, потери: 58.1192\n",
      "Эпоха: 1, режим: test, потери: 15.4221\n",
      "Эпоха: 2, режим: train, потери: 31.8015\n",
      "Эпоха: 2, режим: test, потери: 13.6195\n",
      "Эпоха: 3, режим: train, потери: 29.6243\n",
      "Эпоха: 3, режим: test, потери: 13.4845\n",
      "Эпоха: 4, режим: train, потери: 29.3206\n",
      "Эпоха: 4, режим: test, потери: 13.4065\n",
      "Эпоха: 5, режим: train, потери: 29.2327\n",
      "Эпоха: 5, режим: test, потери: 13.4727\n",
      "Эпоха: 6, режим: train, потери: 29.1847\n",
      "Эпоха: 6, режим: test, потери: 13.4631\n",
      "Эпоха: 7, режим: train, потери: 29.1586\n",
      "Эпоха: 7, режим: test, потери: 13.4997\n",
      "Эпоха: 8, режим: train, потери: 29.1222\n",
      "Эпоха: 8, режим: test, потери: 13.4521\n",
      "Эпоха: 9, режим: train, потери: 29.1344\n",
      "Эпоха: 9, режим: test, потери: 13.4406\n",
      "Эпоха: 10, режим: train, потери: 29.1310\n",
      "Эпоха: 10, режим: test, потери: 13.4744\n"
     ]
    }
   ],
   "source": [
    "# Обучение и тест\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for mode in ['train', 'test']:\n",
    "        if mode == 'train':\n",
    "            model.train()\n",
    "            my_loader = train_loader\n",
    "        else:\n",
    "            model.eval()\n",
    "            my_loader = test_loader\n",
    "\n",
    "        current_loss = 0\n",
    "        for i, (x, y) in enumerate(my_loader):\n",
    "            x, y  = x.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(mode == 'train'):\n",
    "                outputs = model(x, y)\n",
    "                l = loss(outputs.permute(1, 2, 0), y)\n",
    "\n",
    "                if mode == 'train':\n",
    "                    l.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            current_loss += l.item()\n",
    "\n",
    "        print(f'Эпоха: {epoch+1}, режим: {mode}, потери: {current_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
